{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Approximate Local Text Explanation (ALTE) - IMDb movie review sentiment explanation\n",
    "Explaining an IMDb Movie Reviews Text Classification Tensorflow Model localy for one datapoint with Approximate Local Text Explanation via linear models. This is a local explanation procedure in which a single input data point is analyzed. The components of this input data point (token) are activated or deactivated by permutations of a binary vector of the same size as the number of components of the input data point. All permutations are classified by the original classification model and stored in a meta dataset. This meta dataset is then used to train a linear classification model, thus linearly approximating the original classification function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports and Configuration\n",
    "For the original classification model we use TensorFlow, for the dataset and its transformation TensorFlow Dataset and Pandas Dataframe, for mathemathical operations Numpy and text processing RegEx and String libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Embedding, Dropout, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.python.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.python.keras.metrics import BinaryAccuracy\n",
    "from ate.base import ALTE, ATE_Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration by TensorFlow tutorial \"Basic Text Classification\":\n",
    "- MAX_FEATURES = Vocabulary size\n",
    "- EMBEDDING_DIM = Token embedding vector size\n",
    "- SEQUENCE_LENGTH = Max. tokens for classification\n",
    "- BATCH_SIZE = Dataset batching size\n",
    "- AUTOTUNE = Buffer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 10000\n",
    "EMBEDDING_DIM = 16\n",
    "SEQUENCE_LENGTH = 250\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading and Preparation\n",
    "Initial downloading of IMDb movie review dataset by usind TensorFlow Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 12:50:26.134844: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-25 12:50:26.134933: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "raw_train_ds = tfds.load('imdb_reviews', split='train').batch(BATCH_SIZE)\n",
    "raw_test_ds = tfds.load('imdb_reviews', split='test').batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a **custom standardization** function to process the textual data and stripping html tags and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorization** of the textual data by using a vocabulary and transforming the tokens into integer ids (id vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=MAX_FEATURES,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 12:50:26.208880: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-03-25 12:50:26.255362: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "train_text = raw_train_ds.map(lambda x: x['text'])\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(lambda x: vectorize_text(x['text'], x['label']))\n",
    "test_ds = raw_test_ds.map(lambda x: vectorize_text(x['text'], x['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creating and Training\n",
    "Creation and trainig of the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(MAX_FEATURES + 1, EMBEDDING_DIM),\n",
    "    Dropout(0.2),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=BinaryCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=BinaryAccuracy(threshold=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 12:50:28.258956: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 15s 18ms/step - loss: 0.6487 - binary_accuracy: 0.7178\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.5003 - binary_accuracy: 0.8236\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.3931 - binary_accuracy: 0.8628\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.3310 - binary_accuracy: 0.8820\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.2898 - binary_accuracy: 0.8973\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/782 [..............................] - ETA: 8s - loss: 0.3746 - binary_accuracy: 0.8125  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 12:51:21.463911: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 4ms/step - loss: 0.3368 - binary_accuracy: 0.8637\n",
      "Loss:  0.33678048849105835\n",
      "Accuracy:  0.8636800646781921\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Explaining\n",
    "Initializing ALTE by providing the Tokinization, Vectorization (only needed for post-processing to identify token similarities), Classification Function. Additionaly initializing the ATE_Options with the column names, permutation (approximation) steps, permutation border (per step), classes (1 for binary; >2 for multi-class/-label), linear epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    return np.array(x.lower().split())\n",
    "def classify(x):\n",
    "    id_vecs = []\n",
    "    for e in x['text'].tolist():\n",
    "        id_vec = []\n",
    "        if len(e) > 0:\n",
    "            id_vec = vectorize_layer(' '.join(e)).numpy().tolist()\n",
    "        if len(id_vec) == 0:\n",
    "            id_vec = [0]*SEQUENCE_LENGTH\n",
    "        id_vecs.append(id_vec)\n",
    "    return model.predict(id_vecs)\n",
    "ate = ALTE(\n",
    "    tokenize,\n",
    "    lambda x: x, #INFO: Only needed for effect transformation.\n",
    "    classify,\n",
    ")\n",
    "options = ATE_Options(['text'], 5, 10000, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the **explanation** on one entry from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                        | 0/5 [00:00<?, ?it/s]2023-03-25 12:51:26.227891: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 12:51:26.509800: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 65ms/step - loss: 0.1806 - accuracy: 0.4969\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1763 - accuracy: 0.5031\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1732 - accuracy: 0.5220\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1706 - accuracy: 0.5535\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1678 - accuracy: 0.5660\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1657 - accuracy: 0.5660\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1638 - accuracy: 0.5723\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1619 - accuracy: 0.5849\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1601 - accuracy: 0.6101\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1583 - accuracy: 0.6226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████████████████▊                                                                                                                   | 1/5 [00:02<00:09,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1807 - accuracy: 0.6189\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0986 - accuracy: 0.7597\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0398 - accuracy: 0.8340\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.0174 - accuracy: 0.8626\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.0654 - accuracy: 0.8824\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.1031 - accuracy: 0.8961\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.1353 - accuracy: 0.9016\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.1637 - accuracy: 0.9077\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.1900 - accuracy: 0.9116\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.2146 - accuracy: 0.9147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████████████████████████████▌                                                                                      | 2/5 [01:40<02:55, 58.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.2141 - accuracy: 0.9192\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.2375 - accuracy: 0.9222\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.2599 - accuracy: 0.9241\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.2827 - accuracy: 0.9251\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.3041 - accuracy: 0.9255\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.3261 - accuracy: 0.9267\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.3474 - accuracy: 0.9268\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.3696 - accuracy: 0.9274\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.3916 - accuracy: 0.9302\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.4130 - accuracy: 0.9267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████████████████████████████████████████▍                                                         | 3/5 [03:18<02:33, 76.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.4795 - accuracy: 0.9193\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.5077 - accuracy: 0.9237\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.5351 - accuracy: 0.9230\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.5621 - accuracy: 0.9242\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.5889 - accuracy: 0.9235\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.6146 - accuracy: 0.9238\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.6409 - accuracy: 0.9256\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.6665 - accuracy: 0.9232\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: -0.6922 - accuracy: 0.9247\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 2s 7ms/step - loss: -0.7178 - accuracy: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 4/5 [04:52<01:23, 83.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 2s 7ms/step - loss: -0.6615 - accuracy: 0.9319\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 2s 8ms/step - loss: -0.6842 - accuracy: 0.9316\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 3s 9ms/step - loss: -0.7068 - accuracy: 0.9318\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 3s 8ms/step - loss: -0.7288 - accuracy: 0.9339\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 3s 8ms/step - loss: -0.7510 - accuracy: 0.9331\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 3s 9ms/step - loss: -0.7728 - accuracy: 0.9319\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 3s 9ms/step - loss: -0.7942 - accuracy: 0.9339\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 3s 9ms/step - loss: -0.8157 - accuracy: 0.9344\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 3s 9ms/step - loss: -0.8376 - accuracy: 0.9341\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 3s 9ms/step - loss: -0.8593 - accuracy: 0.9359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [06:34<00:00, 78.98s/it]\n"
     ]
    }
   ],
   "source": [
    "test_df = tfds.as_dataframe(raw_test_ds).head(1)\n",
    "test_df = pd.DataFrame([test_df['text'][0][0].decode('UTF-8')], columns=['text'])\n",
    "effects = ate.explain(test_df, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Result\n",
    "With little data (one datapoint) and moderate calculation power (M1 Macbook Pro) the approach is able to identify tokens with different effects on the classification. Tokens with negative effects tend towards a negativ sentiment and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>effect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there</td>\n",
       "      <td>-1.688185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>make</td>\n",
       "      <td>-2.893196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it</td>\n",
       "      <td>1.708110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dead;</td>\n",
       "      <td>-1.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>smith,</td>\n",
       "      <td>1.967181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rodriguez,</td>\n",
       "      <td>1.523124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>amazing</td>\n",
       "      <td>7.405206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>flawless</td>\n",
       "      <td>4.487193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>and</td>\n",
       "      <td>1.763144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>and</td>\n",
       "      <td>1.715159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>any</td>\n",
       "      <td>-3.985820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>haven't</td>\n",
       "      <td>1.938803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>(and,</td>\n",
       "      <td>1.678385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>even</td>\n",
       "      <td>-3.916845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>then,</td>\n",
       "      <td>-2.985782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>don't</td>\n",
       "      <td>-2.794823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>think</td>\n",
       "      <td>2.251531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>quite</td>\n",
       "      <td>1.863472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>talent</td>\n",
       "      <td>-1.899983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>would</td>\n",
       "      <td>-2.178223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>sit</td>\n",
       "      <td>-2.397144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>down</td>\n",
       "      <td>-1.751200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>copy</td>\n",
       "      <td>2.262736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>script</td>\n",
       "      <td>-5.888813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>and</td>\n",
       "      <td>1.746225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>do</td>\n",
       "      <td>-2.398235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>it</td>\n",
       "      <td>1.805234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>fully</td>\n",
       "      <td>1.500536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>appreciate</td>\n",
       "      <td>3.150918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>uh,</td>\n",
       "      <td>-1.625906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>and</td>\n",
       "      <td>1.688619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>it.</td>\n",
       "      <td>1.677606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>beautifully</td>\n",
       "      <td>5.120149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>sign</td>\n",
       "      <td>-1.700697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>director),</td>\n",
       "      <td>-3.060520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>and</td>\n",
       "      <td>1.637904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>performances</td>\n",
       "      <td>2.701107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>solid</td>\n",
       "      <td>4.403421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>(there's</td>\n",
       "      <td>-1.740799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>none</td>\n",
       "      <td>-4.700369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word    effect\n",
       "0           there -1.688185\n",
       "4            make -2.893196\n",
       "9              it  1.708110\n",
       "15          dead; -1.805970\n",
       "18         smith,  1.967181\n",
       "22     rodriguez,  1.523124\n",
       "32        amazing  7.405206\n",
       "34       flawless  4.487193\n",
       "36            and  1.763144\n",
       "39            and  1.715159\n",
       "43            any -3.985820\n",
       "49        haven't  1.938803\n",
       "59          (and,  1.678385\n",
       "60           even -3.916845\n",
       "61          then, -2.985782\n",
       "63          don't -2.794823\n",
       "64          think  2.251531\n",
       "67          quite  1.863472\n",
       "74         talent -1.899983\n",
       "87          would -2.178223\n",
       "90            sit -2.397144\n",
       "91           down -1.751200\n",
       "94           copy  2.262736\n",
       "97         script -5.888813\n",
       "98            and  1.746225\n",
       "99             do -2.398235\n",
       "104            it  1.805234\n",
       "106         fully  1.500536\n",
       "107    appreciate  3.150918\n",
       "109           uh, -1.625906\n",
       "111           and  1.688619\n",
       "114           it.  1.677606\n",
       "118   beautifully  5.120149\n",
       "122          sign -1.700697\n",
       "126    director), -3.060520\n",
       "127           and  1.637904\n",
       "129  performances  2.701107\n",
       "133         solid  4.403421\n",
       "134      (there's -1.740799\n",
       "135          none -4.700369"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effect_df = pd.DataFrame(effects, columns=['word', 'effect'])\n",
    "effect_df['effect'] = effect_df['effect'].apply(lambda x: x[0])\n",
    "effect_df[(effect_df['effect'] > 1.5) | (effect_df['effect'] < -1.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
