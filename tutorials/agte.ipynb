{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Approximate Global Text Explaination (AGTE)\n",
    "Explaining an IMDb Movies Text Classification Tensorflow Model globally for a dataset with Approximate Global Text Explaination via linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Embedding, Dropout, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.python.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.python.keras.metrics import BinaryAccuracy\n",
    "from ate.base import AGTE, ATE_Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 10000\n",
    "EMBEDDING_DIM = 16\n",
    "SEQUENCE_LENGTH = 250\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_ds = tfds.load('imdb_reviews', split='train').batch(BATCH_SIZE)\n",
    "raw_test_ds = tfds.load('imdb_reviews', split='test').batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=MAX_FEATURES,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = raw_train_ds.map(lambda x: x['text'])\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(lambda x: vectorize_text(x['text'], x['label']))\n",
    "test_ds = raw_test_ds.map(lambda x: vectorize_text(x['text'], x['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(MAX_FEATURES + 1, EMBEDDING_DIM),\n",
    "    Dropout(0.2),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=BinaryCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=BinaryAccuracy(threshold=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ate = AGTE(\n",
    "    lambda x: np.array(x.lower().split()),\n",
    "    lambda x: x, #INFO: Only needed for effect transformation.\n",
    "    lambda x: model.predict([vectorize_layer(' '.join(e)).numpy().tolist() if len(e) > 0 else [0]*SEQUENCE_LENGTH for e in x['text'].tolist()])\n",
    ")\n",
    "options = ATE_Options(['text'], 2, 100, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = tfds.as_dataframe(raw_test_ds).head(10)\n",
    "test_df = pd.DataFrame([i['text'][0].decode('UTF-8') for _, i in test_df.iterrows()], columns=['text'])\n",
    "effects = ate.transform_effects(ate.explain(test_df, options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(effects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
